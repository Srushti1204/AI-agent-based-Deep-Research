{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_together import ChatTogether\n",
        "from langgraph.graph import StateGraph, END\n",
        "from tavily import TavilyClient\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"cc9d912a47b3e176be7b130a25fa6872088da3c3b75340b77091153fe2acb78b\"\n",
        "\n",
        "tavily_client = TavilyClient()\n",
        "\n",
        "def search_tavily(query: str):\n",
        "    result = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n",
        "    return result['results']\n",
        "\n",
        "llm = ChatTogether(\n",
        "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",  # Good quality open-source model\n",
        "    temperature=0.2,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "#AGENT 1\n",
        "def researcher_node(state):\n",
        "    query = state['query']\n",
        "    links = search_tavily(query)\n",
        "\n",
        "    documents = \"\\n\".join([f\"Title: {link['title']}\\nURL: {link['url']}\\nSnippet: {link['content']}\" for link in links])\n",
        "    return {\"query\": query, \"documents\": documents}\n",
        "\n",
        "#AGENT 2:\n",
        "def answer_drafter_node(state):\n",
        "    query = state['query']\n",
        "    documents = state['documents']\n",
        "\n",
        "    response = llm.invoke([\n",
        "        SystemMessage(content=\"You are a helpful research assistant. Use the documents below to answer the question clearly.\"),\n",
        "        HumanMessage(content=f\"Question: {query}\\n\\nDocuments:\\n{documents}\")\n",
        "    ])\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"documents\": documents,\n",
        "        \"answer\": response.content\n",
        "    }\n",
        "workflow = StateGraph(dict)\n",
        "workflow.add_node(\"research_agent\", researcher_node)\n",
        "workflow.add_node(\"answer_drafter\", answer_drafter_node)\n",
        "workflow.set_entry_point(\"research_agent\")\n",
        "workflow.add_edge(\"research_agent\", \"answer_drafter\")\n",
        "workflow.add_edge(\"answer_drafter\", END)\n",
        "workflow = workflow.compile()\n",
        "\n",
        "\n",
        "def run_deep_research_agentic_system(user_query):\n",
        "    inputs = {\"query\": user_query}\n",
        "    result = workflow.invoke(inputs)\n",
        "    return result[\"answer\"]\n",
        "\n",
        "query = \"What are the upcoming updates of LLM?\"\n",
        "final_answer = run_deep_research_agentic_system(query)\n",
        "print(\"\\n--- FINAL ANSWER ---\\n\")\n",
        "print(final_answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFAx9BZV7hls",
        "outputId": "23f74eb6-e347-49d2-9bbf-b759fe499fa2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- FINAL ANSWER ---\n",
            "\n",
            " Based on the documents provided, the following upcoming updates for Large Language Models (LLMs) in 2025 are:\n",
            "\n",
            "1. GPT-4.5 by OpenAI, release date: Feb 27, 2025.\n",
            "2. Claude 3.7 Sonnet by Anthropic, release date: Feb 24, 2025.\n",
            "3. Grok-3 by xAI, release date: Feb 17, 2025.\n",
            "4. Gemini 2.0 Flash-Lite and Gemini 2.0 Pro by Google DeepMind, release date: Feb 5, 2025.\n",
            "5. GPT-o3-mini by OpenAI, release date: Jan 31, 2025.\n",
            "6. Qwen 2.5-Max by Alibaba, release date: Jan 29, 2025.\n",
            "\n",
            "In addition to these releases, there are also updates regarding the capabilities and features of LLMs:\n",
            "\n",
            "* LLaMA 3.2 by Meta, released in September 2024, introduces multimodal capabilities for processing both text and images.\n",
            "* Gemini 2.0 Pro and Gemini 2.0 Flash have an increased context length of 2,000,000 and 1,000,000 tokens, respectively.\n",
            "* LLaMA 3.1 has 405 billion parameters and an expanded context length of 128,000.\n",
            "\n",
            "Lastly, there are trends and innovations shaping the future of AI LLMs, including the emergence of more efficient architectures. However, specific details about these updates are not provided in the documents.\n"
          ]
        }
      ]
    }
  ]
}